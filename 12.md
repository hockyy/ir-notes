### Search Engine Evaluation

## Online evaluation

- A/B Testing
  - Merupakan suatu eksperimen terkontrol untuk menguji apakah perubahan yang terjadi lebih baik atau tidak dari perubahan perilaku pengguna.
  - Penanda sukses search engine adalah:
    - Click (Banyak relevan)
    - Query Reformulation (Keywordnya diganti)
    - Waktu melihat halaman / SERP
  - Punya dua sistem yang berbeda, dua-duanya dimasukkan ke dalam production environment,
  - Kita rekam behaviornya
- Interleaving
  - Hasilnya kita selang seling:
    - Rank 1 Sistem A
    - Rank 1 Sistem B
    - Rank 2 Sistem A
    - Rank 2 Sistem B

### Offline Evaluation

Sudah ada test datanya, ada perangkat dokumen, queries, dan judgements yang sudah precomputed, biasanya biner, antara relevan atau tidak. Judgements ini biasanya bersifat subjektif dan dapat dibuat oleh manusia.

Relevance Judgments (qrels): Menunjukkan hubungan query sama docs relevan atau ga. Qrels dibuat oleh manusia.

Perlu sebuah metric yang menilai kualitas dari sebuah ranking yang dihasilkan.

**Precision**: dari himpunan dokuemn yang di retrieve, berapa yang relevan

**Recall**, dari himpunan dokumen yang relevan, ada berapa proporsi yang berhasil diretrieve.

F1 bukan metric yang baik untuk information retrieval.

Metric itu tergantung dari behavior kita, kalau misalkan kita ingin melihat suatu search engine untuk hasil yang satu doang, itu dia lebih baik kalau yang relevan di atas, selain itu, lebih baik kalau hasil relevan lebih banyak meskipun tidak nomor 1.

### Metric Based on User Model

Misal ranking/SERP: $\vec{r} = [r_1, r_2, \dots]$

Ada discount function:
$$
M@K(\vec{r}) = \sum_{i = 1}^k D(i). r_i
$$
Secara practice, biasanya $K = 1000$

## Discounted Cumulative Gain (DCG)

Perhatikan bahwa $D(i)$ menurun saat i menaik, sebuah discount function proporsional terhadap probabilitas user inspeksi posisi rank i.
$$
DCG@K(\vec{r}) =  \sum_{i = 1}^k \frac{r_i}{\log_2(i + 1)}
$$
Interpretasinya adalah expected total volume of relevance atau total gain yang dikumpulakn oleh seorang user saat melakukan pencarian sebuah query.

Ini versi modifikasi yang diusulkan peneliti microsoft.

### Rank Biased Precision

$$
RBP@K(\vec{r};p) =  \sum_{i = 1}^k (1 - p).p^{(i - 1)} . r_i
$$

Biasanya dipilih 0.8 p nya.

p adalah parameter yang merepresentasikan “tingkat kesabaran user” saat inspeksi SERP. Biasanya pakai p = 0.8.

p tinggi: user dengan senang hati inspeksi sampai dokumen ranking bawah

p rendah: user hanya mau inspeksi dokumen di ranking atas saja



### Precision

$$
Prec@K(\vec{r};p) =  \sum_{i = 1}^k \frac{1}{K}.r_i
$$



### Average Precision

$$
AP@K(\vec{r};p) =  \sum_{i = 1}^k \frac{Prec@i(
\vec{r})}{R}.r_i
$$



R adalah banyakanya dokumen relevan di koleksi, R biasanya jarang diketahui dan diaproksimasi sebagai $R = \sum_{i = 1}^K r_i$

### Query Expansion

Ada masalah konsep sama yang direpresentasikan oleh banyak term,

- Synonymity
- Misspellings
- Acronym
- Word Stemmings

### Vocabulary Mismatch

Bisa memperburuk recall, ada dokumen relevan yang ga diacquire, padahal konsepnya sama, hanya saja termnya berbeda.

Jika tidak ditangani, user biasanya secara manual akan melakukan query reformulation. untuk memperbaiki query sebelumnya, bisa ga proses ini kita bikin otomatis atau semi otomatis, kita harus bantu user sebisa mungkin.

- Local Methods
  - Bergantung kepada dokumen yang sebelumnya dikembalikan untuk menjawab query ptertama.
  - Relevance Feedback
  - Pseudo Relevance Feedback
- Global Methods (User tidak sadar querynya diexapnd)
  -  Tidak bergantung kepada hasil yang dikembalikan terhadap query pertama.
  - Query expansion/reformulation dengan Wordnet (Thesaurus)
  - Query expansion dengan hasil spelling correction

Query expansion bakal diexpand ke beberapa konteks/intend

### Relevance Feedback

RF melibatkan user untuk memperbaiki SERPs

1. Usernya memberikan isu yang singkat dan pendek, konteksnya masih belum teralu jelas
2. Sistem mengambalikan initial set hasil,
3. **Pengguna disini akan menandai yang relevan mana dan tidak**
4. Sistem melakukan komputasi representasi yang lebih baik untuk setiap feedback,
5. Sistem mengembalikan atau menampilkan hasil revisi dari himpunan hasil.

Feedback pengguna secara eksplisit diperlukan
